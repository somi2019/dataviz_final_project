---
title: "Visualizing Text and Distributions"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_float: true
---

# Data Visualization Project 03


In this exercise you will explore methods to visualize text data and practice how to recreate charts that show the distributions of a continuous variable. 


## Part 1: Density Plots

Using the dataset obtained from FSU's [Florida Climate Center](https://climatecenter.fsu.edu/climate-data-access-tools/downloadable-data), for a station at Tampa International Airport (TPA) from 2016 to 2017, attempt to recreate the charts shown below

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
Tampa_Weather<-read_csv("https://github.com/reisanar/datasets/raw/master/tpa_weather_16_17.csv")
sample_n(Tampa_Weather,4)
```

```{r}
library(lubridate)
tpa_clean <- Tampa_Weather %>% 
  unite("doy", year, month, day, sep = "-") %>% 
  mutate(doy = ymd(doy), 
         max_temp = as.double(max_temp), 
         min_temp = as.double(min_temp), 
         precipitation = as.double(precipitation))
```
```{r}
month.names <-c('1'="January",'2'="February",'3'="March",'4'="April",'5'="May",'6'="June",'7'="July",'8'="August",'9'="September",'10'="October",'11'="Novomber",'12'="December")
```


(a) 
```{r}
Tampa_Weather %>%
ggplot(Tampa_Weather,mapping=aes(x=max_temp,fill=as.factor(month))) +
geom_histogram(color="white",binwidth = 3) +
theme(axis.text.x = element_text(angle = 90, hjust = 1,vjust = 0.5, size = 12), 
axis.text.y = element_text(size = 12),strip.text = element_text(size = 12),axis.title = element_text(size = 12))+ facet_wrap(~ month,labeller =as_labeller(month.names) )+theme(legend.position="none")+
labs(x = "Maximum Temperature",y = "Number of Days",title = "Density of Hottest Days in Tampa ")+
theme(plot.title = element_text(size = 20, face = "bold",color="black"))+scale_fill_manual(values=c("#450D54","#450D54","#433E85","#433E85","#2D708E","#2D708E","#1E9B8A","#1E9B8A","#1E9B8A","#C2DF23","#C2DF23","#FDE725"))


```
* According to the plot in months of **June** and **July** Tampa had most frequency of hot days.


(b) 
```{r}

ggplot(data =Tampa_Weather,mapping = aes(x = max_temp)) +
geom_density(bw=0.5,fill="#808080", color="black",kernel="epanechnikov")+ 
theme(axis.text.x = element_text(angle = 90, hjust = 1,vjust = 0.5, size = 10), 
 axis.text.y = element_text(size = 12),strip.text = element_text(size = 12),axis.title = element_text(size = 12))+ 
labs(x = "Maximum Temperature",y = "Number of Days",title = "Density of Hottest Days in Tampa ")+ theme(plot.title = element_text(size = 20, face = "bold",color="tomato"))+theme_minimal()

```
* In hottest days maximum of temperature achived to **90** degree of Fahrenheit. 



(c) 
```{r  }

ggplot(Tampa_Weather,aes(x=max_temp)) +
geom_density(binwidth = 3,fill="purple") +
theme(axis.text.x = element_text(angle = 90, hjust = 1,vjust = 0.5, size = 12), 
 axis.text.y = element_text(size = 12),strip.text = element_text(size = 12),axis.title = element_text(size = 12)) +facet_wrap(~ month,labeller =as_labeller(month.names))+
labs(x = "Maximum Temperature",y = "Number of Days",title = "Density plot for each month in 2016 ")+theme(plot.title = element_text(size = 20, face = "bold",color="black"))

```

* According to this plot it could be find in every month how many days had maximun of temperature.


```{r}
library(ggridges)
```


(d) 
```{r}
Tampa_Weather$month<-factor(Tampa_Weather$month,levels = c("1","2","3","4","5","6","7","8","9","10","11","12"))
Tampa_Weather<-Tampa_Weather[order(Tampa_Weather$month),]
ordered_months <- c("January","February","March","April","May","June","July","August","september","October","Novomber","December")
Tampa_Weather$months<-ordered_months[Tampa_Weather$month]
Tampa_Weather$months<-factor(Tampa_Weather$months,levels = c("January","February","March","April","May","June","July","August","september","October","Novomber","December"))
Tampa_Weather<-Tampa_Weather[order(Tampa_Weather$months),]
ggplot(data=Tampa_Weather,mapping=aes(x=max_temp,y=months, fill=months))+ stat_density_ridges(quantile_lines = TRUE, quantiles = 0.5,show.legend = FALSE)+labs(x = "Maximum Temperature", y = NULL,
 title = "Temperature Distribution in different months")+ theme_bw()+
theme(title = element_text(size = 16, face = "bold"))+scale_fill_manual(values=c("#450D54","#482173","#433E85","#4C6996","#2D708E","#25858E","1e9B8A","#2CB07F","#51C56A","#85D54A","#C2DF23","#FDE725"))

```

* This plot shows in months of **January**,**February** and **December** temperature in Tampa had a wide distribution.

(e) 
```{r}
ggplot(data=Tampa_Weather,mapping=aes(x=max_temp,y=months, fill=months))+geom_density_ridges(show.legend = FALSE)+ stat_density_ridges(quantile_lines=TRUE,quantiles=0.5,show.legend = FALSE)+labs(x = "Maximum Temperature", y = NULL,
 title = "Temperature Distribution in different months")+ theme_minimal()+
theme(title = element_text(size = 16, face = "bold"))+scale_fill_manual(values=c("#450D54","#482173","#433E85","#4C6996","#2D708E","#25858E","1e9B8A","#1e9B8A","#1e9B8A","#85D54A","#C2DF23","#FDE725"))
```

* The graph shows in **August** and **July** the temperature was maximum.


```{r}
library(viridis)
```

(f)
```{r}
ggplot(Tampa_Weather,aes(x=max_temp,y=months,fill=stat(x)))+geom_density_ridges_gradient(scale=1.75,size=0.6,quantile_lines=TRUE,quantiles=0.5)+scale_fill_viridis(
                     , name = "Maximum Temperature"
                     , option = "plasma")+labs(x="Maximum Temperature in Farenheit Degree",y="Month")+theme_minimal()
```

* The graph shows in **August** and **July** the temperature was maximum.





## Part 2: Visualizing Text Data


```{r}
library(tidyverse)
billboard<-read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/BB_top100_2015.csv")
```


```{r}
library(tidytext)
```


```{r}
head(billboard,8)
```



```{r}
#To see the columns in the data frame:

names(billboard) 
 
```

```{r}
dim(billboard)
```
```{r}
#To see how they are structured,choose lyrics column for one of the songs as a sample
str(billboard[100, ]$Lyrics, nchar.max = 50)
```
```{r}
# convert everything to lower case
billboard$Lyrics <- sapply(billboard$Lyrics, tolower)
```


```{r}
summary(billboard)
```

```{r}
billboard <- billboard %>%
  mutate(chart_level = ifelse(billboard$Rank %in% 1:10, "Top 10", 
           ifelse(billboard$Rank %in% 11:100, "Top 100", "Uncharted")))
```


```{r}
#Filtering top 10 songs:
billboard %>%
  filter(Rank <= 10 )
  
```


After creating plots I noticed there were some redundant characters in the text,so I tried to git rid of them by bellow function:
```{r}
Redundant_words <- c("meaning","youre","wanna","byjamesg","gotta","gonna","nigga","didnt","whats","niggas","bitch","dont","yeah","aint","wont")
```

Also using **stop_words** function to filter some specific words:
```{r}
head(sample(stop_words$word, 30), 30)

```

```{r}
##unnest and remove stop, undesirable and short words

billboard <- billboard %>%
  unnest_tokens(word, Lyrics) %>%
  anti_join(stop_words) %>%
  distinct() %>%
  filter(!word %in% Redundant_words) %>%
  filter(nchar(word) >= 4)
```


#Look for top words frequency


#Top Words
In order to do a simple evaluation of the most frequently used words in the full set of lyrics, you can use count() and top_n() to get the n top words from your clean, filtered dataset. 

```{r}
billboard %>%
  count(word, sort = TRUE) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot() +
    geom_col(aes(word, n), fill ="pink") +
    theme(legend.position = "none", 
          plot.title = element_text(hjust = 0.5),
          panel.grid.major = element_blank()) +
    ylab("Song Count") +
    ggtitle("Most Frequently Used Words in billboard Lyrics") +
    coord_flip()
```


#Popular Words


```{r}
popular_words <- billboard %>% 
  group_by(chart_level) %>%
  count(word, chart_level, sort = TRUE) %>%
  slice(seq_len(8)) %>%
  ungroup() %>%
  arrange(chart_level,n) %>%
  mutate(row = row_number()) 

popular_words %>%
  ggplot(aes(row, n, fill = chart_level)) +
    geom_col(show.legend = NULL) +
    labs(x = NULL, y = "Song Count") +
    ggtitle("Popular Words by Chart Level") + 
    facet_wrap(~chart_level, scales = "free") +
    scale_x_continuous(  # This handles replacement of row 
      breaks = popular_words$row, # notice need to reuse data frame
      labels = popular_words$word) +
    coord_flip()

```

```{r}
popular_tfidf_words <- billboard %>%
  unnest_tokens(word, Song) %>%
  distinct() %>%
  filter(!word %in% Redundant_words) %>%
  filter(nchar(word) >= 4) %>%
  count(chart_level, word, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(word, chart_level, n)
head(popular_tfidf_words)
```
#TF-IDF
 Using TF-IDF certainly gives us a different perspective on potentially important words.

```{r}
top_popular_tfidf_words <- popular_tfidf_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  group_by(chart_level) %>% 
  slice(seq_len(8)) %>%
  ungroup() %>%
  arrange(chart_level, tf_idf) %>%
  mutate(row = row_number())

top_popular_tfidf_words %>%
  ggplot(aes(x = row, tf_idf, 
             fill = chart_level)) +
    geom_col(show.legend = NULL) +
    labs(x = NULL, y = "TF-IDF") + 
    ggtitle("Important Words using TF-IDF by Chart Level") +
    facet_wrap(~chart_level, ncol = 3, scales = "free") +
    scale_x_continuous(  # This handles replacement of row 
      breaks = top_popular_tfidf_words$row, # notice need to reuse data frame
      labels = top_popular_tfidf_words$word) +
    coord_flip()
```

# Conclusion
In this project, after checking the basics features and performing some actions such as data cleansing and removing uninformative words,an exploratory analysis was begun to categorize song levels.

Next,text visualizing was checked by unnesting lyrics into tokenized words so it was possible to look at lyric complexity. The results provide critical insights for the next steps of **sentiment analysis** and topic modeling.

Finally,**TF-IDF analysis**  was used to represent the information behind a word in a document relating to some outcome of interest. Result may look interesting, but it could be only some part od the whole story.
* use of **slice(seq_len(n))** to grab the first n words in each chart_level. 
* use **bind_tf_idf()** to run the formulas and create new columns.
